{{- range $index, $coordinator := .Values.coordinators }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: memgraph-coordinator-{{ $coordinator.id }}
  labels:
    {{- with $.Values.labels.coordinators.statefulSetLabels }}
    {{- toYaml . | nindent 4 }}
    {{- end }}

spec:
  serviceName: "memgraph-coordinator-{{ $coordinator.id }}"
  replicas: 1
  selector:
    matchLabels:
      app: memgraph-coordinator-{{ $coordinator.id }}
      role: coordinator
  {{- with $.Values.updateStrategy }}
  updateStrategy:
  {{ toYaml . | nindent 4 }}
  {{- end }}
  template:
    metadata:
      labels:
        app: memgraph-coordinator-{{ $coordinator.id }}
        role: coordinator
        {{- with $.Values.labels.coordinators.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      terminationGracePeriodSeconds: {{ $.Values.container.coordinators.terminationGracePeriodSeconds }}
      securityContext:
        runAsUser: {{ $.Values.memgraphUserId }}
        runAsGroup: {{ $.Values.memgraphGroupId }}
        fsGroup: {{ $.Values.memgraphGroupId }}
      {{- with $.Values.tolerations.coordinators }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      affinity:
        {{- if $.Values.affinity.nodeSelection }}
        # Node Selection Affinity: Scheduled on nodes with specific label key and value
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: {{ $.Values.affinity.roleLabelKey }}
                operator: In
                values:
                - {{ $.Values.affinity.coordinatorNodeLabelValue }}
        podAntiAffinity :
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: role
                operator: In
                values:
                - coordinator
            topologyKey: "kubernetes.io/hostname"
        {{- else if $.Values.affinity.unique }}
        # Unique Affinity: Schedule pods on different nodes
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: role
                operator: In
                values:
                - coordinator
                - data
            topologyKey: "kubernetes.io/hostname"
        {{- else if $.Values.affinity.parity }}
        # Parity Affinity: One coordinator and one data node per node, coordinator schedules first, needs to be in pairs
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: role
                operator: In
                values:
                - coordinator
            topologyKey: "kubernetes.io/hostname"
        {{- else }}
        # Default Affinity: Avoid scheduling on the same node
        podAntiAffinity:
           preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 50
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: role
                      operator: In
                      values:
                        - coordinator
                topologyKey: "kubernetes.io/hostname"
        {{- end }}
      initContainers:
      {{- if $.Values.sysctlInitContainer.enabled }}
      - name: init-sysctl
        image: "{{ $.Values.sysctlInitContainer.image.repository }}:{{ $.Values.sysctlInitContainer.image.tag }}"
        imagePullPolicy: {{ $.Values.sysctlInitContainer.image.pullPolicy }}
        command: ['sh', '-c', 'sysctl -w vm.max_map_count={{ $.Values.sysctlInitContainer.maxMapCount }}']
        securityContext:
          privileged: true
          runAsUser: 0
      {{- end }}

      {{- if $.Values.storage.coordinators.createCoreDumpsClaim }}
      - name: init-core-dumps
        image: busybox
        command: ['/bin/sh', '-c']
        args:
          - >
            echo '{{ $.Values.storage.coordinators.coreDumpsMountPath }}/core.%e.%p.%t.%s' | tee /proc/sys/kernel/core_pattern;
            if [ -d /proc/sys/kernel/yama ]; then echo '0' | tee /proc/sys/kernel/yama/ptrace_scope; fi
        securityContext:
          privileged: true
          runAsUser: 0
      {{- end }}

      {{- with $.Values.initContainers.coordinators }}
      {{- toYaml . | nindent 6 }}
      {{- end }}

      containers:
      - name: memgraph-coordinator
        image: "{{ $.Values.image.repository }}:{{ $.Values.image.tag }}"
        imagePullPolicy: {{ $.Values.image.pullPolicy }}
        ports:
        - containerPort: {{ $.Values.ports.boltPort }}
        - containerPort: {{ $.Values.ports.managementPort }}
        - containerPort: {{ $.Values.ports.coordinatorPort }}
        args:
        {{- range $arg := $coordinator.args }}
        - "{{ $arg }}"
        {{- end }}
        env:
          {{- if $.Values.secrets.enabled }}
          - name: MEMGRAPH_USER
            valueFrom:
              secretKeyRef:
                name: {{ $.Values.secrets.name }}
                key: {{ $.Values.secrets.userKey }}
          - name: MEMGRAPH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: {{ $.Values.secrets.name }}
                key: {{ $.Values.secrets.passwordKey }}
          {{- end }}
          - name: MEMGRAPH_ENTERPRISE_LICENSE
            value: {{ $.Values.env.MEMGRAPH_ENTERPRISE_LICENSE }}
          - name: MEMGRAPH_ORGANIZATION_NAME
            value: {{ $.Values.env.MEMGRAPH_ORGANIZATION_NAME }}
          {{- with $.Values.extraEnv.coordinators }}
          {{- toYaml . | nindent 10 }}
          {{- end }}
        volumeMounts:
          - name: memgraph-coordinator-{{ $coordinator.id }}-lib-storage
            mountPath: /var/lib/memgraph
          - name: memgraph-coordinator-{{ $coordinator.id }}-log-storage
            mountPath: /var/log/memgraph
          {{- if $.Values.storage.coordinators.createCoreDumpsClaim }}
          - name: memgraph-coordinator-{{ $coordinator.id }}-core-dumps-storage
            mountPath: {{ $.Values.storage.coordinators.coreDumpsMountPath }}
          {{- end }}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: [ "ALL" ]
          # Run by 'memgraph' user as specified in the Dockerfile
        {{- include "container.coordinators.readinessProbe" $.Values.container.coordinators.readinessProbe | nindent 8 }}
        {{- include "container.coordinators.livenessProbe" $.Values.container.coordinators.livenessProbe | nindent 8 }}
        {{- include "container.coordinators.startupProbe" $.Values.container.coordinators.startupProbe | nindent 8 }}
        {{- with $.Values.resources.coordinators }}
        resources:
          {{- toYaml . | nindent 10 }}
        {{- end }}
      {{- with $.Values.userContainers.coordinators }}
      {{- toYaml . | nindent 6 }}
      {{- end }}

  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: memgraph-coordinator-{{ $coordinator.id }}-lib-storage
      spec:
        accessModes:
        - {{ $.Values.storage.coordinators.libStorageAccessMode }}
        storageClassName: {{ $.Values.storage.coordinators.libStorageClassName }}
        {{- if $coordinator.restoreDataFromSnapshot }}
        dataSource:
          name: {{ $coordinator.volumeSnapshotName }}
          kind: VolumeSnapshot
          apiGroup: snapshot.storage.k8s.io
        {{- end }}
        resources:
          requests:
            storage: {{ $.Values.storage.coordinators.libPVCSize }}

    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: memgraph-coordinator-{{ $coordinator.id }}-log-storage
      spec:
        accessModes:
        - {{ $.Values.storage.coordinators.logStorageAccessMode }}
        storageClassName: {{ $.Values.storage.coordinators.logStorageClassName }}
        resources:
          requests:
            storage: {{ $.Values.storage.coordinators.logPVCSize }}

    {{- if $.Values.storage.coordinators.createCoreDumpsClaim }}
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: memgraph-coordinator-{{ $coordinator.id }}-core-dumps-storage
      spec:
        accessModes:
        - "ReadWriteOnce"
        {{- if $.Values.storage.coordinators.coreDumpsStorageClassName }}
        storageClassName: {{ $.Values.storage.coordinators.coreDumpsStorageClassName }}
        {{- end }}
        resources:
          requests:
            storage: {{ $.Values.storage.coordinators.coreDumpsStorageSize }}
    {{- end }}
---
{{- end }}
